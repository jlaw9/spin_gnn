{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context='talk', style='ticks',\n",
    "        color_codes=True, rc={'legend.frameon': False})\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 14 08:49:00 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.82       Driver Version: 440.82       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro GV100        Off  | 00000000:37:00.0 Off |                  Off |\n",
      "| 31%   43C    P2    35W / 250W |   1673MiB / 32508MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0      5869      C   /home/jvermaas/lib/vmd/vmd_LINUXAMD64        311MiB |\n",
      "|    0      6666      G   paraview                                      77MiB |\n",
      "|    0      8098      G   ...t/nrel/apps/paraview/5.6.0/lib/paraview    87MiB |\n",
      "|    0      9462      G   paraview                                     204MiB |\n",
      "|    0     11716      G   paraview                                      47MiB |\n",
      "|    0     16750      G   paraview                                     116MiB |\n",
      "|    0     19337      G   /usr/bin/X                                   199MiB |\n",
      "|    0     27145      G   ...t/nrel/apps/paraview/5.6.0/lib/paraview   168MiB |\n",
      "|    0     34891      C   ...nwilson/miniconda3/envs/mytf/bin/python   445MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "WARNING: infoROM is corrupted at gpu 0000:37:00.0\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "import nfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess_inputs import preprocessor\n",
    "preprocessor.from_json('tfrecords/preprocessor.json')\n",
    "\n",
    "from loss import AtomInfMask, KLWithLogits\n",
    "\n",
    "model = tf.keras.models.load_model(\n",
    "    '20200812_kl_divergence_faster_lr/best_model.hdf5',\n",
    "    custom_objects={**nfp.custom_objects,\n",
    "                    **{'AtomInfMask': AtomInfMask, 'KLWithLogits': KLWithLogits}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_example(example):\n",
    "    parsed = tf.io.parse_single_example(example, features={\n",
    "        **preprocessor.tfrecord_features,\n",
    "        **{'spin': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "           'bur_vol': tf.io.FixedLenFeature([], dtype=tf.string)}})\n",
    "\n",
    "    # All of the array preprocessor features are serialized integer arrays\n",
    "    for key, val in preprocessor.tfrecord_features.items():\n",
    "        if val.dtype == tf.string:\n",
    "            parsed[key] = tf.io.parse_tensor(\n",
    "                parsed[key], out_type=preprocessor.output_types[key])\n",
    "    \n",
    "    # Pop out the prediction target from the stored dictionary as a seperate dict\n",
    "    parsed['spin'] = tf.io.parse_tensor(parsed['spin'], out_type=tf.float64)\n",
    "    parsed['bur_vol'] = tf.io.parse_tensor(parsed['bur_vol'], out_type=tf.float64)\n",
    "    \n",
    "    spin = parsed.pop('spin')\n",
    "    bur_vol = parsed.pop('bur_vol')\n",
    "    targets = {'atom_inf_mask': spin, 'bur_vol': bur_vol}\n",
    "    \n",
    "    return parsed, targets\n",
    "\n",
    "\n",
    "# Here, we have to add the prediction target padding onto the input padding\n",
    "padded_shapes = (preprocessor.padded_shapes(max_atoms=None, max_bonds=None),\n",
    "                 {'atom_inf_mask': [None], 'bur_vol': [None]})\n",
    "\n",
    "padding_values = (preprocessor.padding_values,\n",
    "                  {'atom_inf_mask': tf.constant(np.nan, dtype=tf.float64),\n",
    "                   'bur_vol': tf.constant(np.nan, dtype=tf.float64)})\n",
    "\n",
    "num_train = len(np.load('redf_split.npz', allow_pickle=True)['train'])\n",
    "batch_size = 128\n",
    "atom_features = 128\n",
    "num_messages = 6\n",
    "\n",
    "train_dataset = tf.data.TFRecordDataset('tfrecords_redf/train.tfrecord.gz', compression_type='GZIP')\\\n",
    "    .map(parse_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\\n",
    "    .cache().shuffle(buffer_size=num_train).repeat()\\\n",
    "    .padded_batch(batch_size=batch_size,\n",
    "                  padded_shapes=padded_shapes,\n",
    "                  padding_values=padding_values)\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "valid_dataset = tf.data.TFRecordDataset('tfrecords_redf/valid.tfrecord.gz', compression_type='GZIP')\\\n",
    "    .map(parse_example, num_parallel_calls=tf.data.experimental.AUTOTUNE)\\\n",
    "    .cache().shuffle(buffer_size=500).repeat()\\\n",
    "    .padded_batch(batch_size=batch_size,\n",
    "                  padded_shapes=padded_shapes,\n",
    "                  padding_values=padding_values)\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "spin_prediction = model.output\n",
    "#spin_prediction._name = 'spin'\n",
    "\n",
    "atom_state = model.layers[-5].output\n",
    "bur_vol_bias =  layers.Embedding(preprocessor.atom_classes, 1,\n",
    "                                 name='bur_vol_bias', mask_zero=True)(model.inputs[0])\n",
    "atom_state = layers.Dense(1, name='bur_vol_dense')(atom_state)\n",
    "bur_vol_prediction = layers.Add(name='bur_vol')([atom_state, bur_vol_bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(model.inputs, [spin_prediction, bur_vol_prediction])\n",
    "learning_rate = tf.keras.optimizers.schedules.InverseTimeDecay(1E-4, 1, 1E-5)\n",
    "model.compile(loss={'atom_inf_mask': KLWithLogits(), 'bur_vol': nfp.masked_mean_absolute_error},\n",
    "              loss_weights={'atom_inf_mask': 1, 'bur_vol': 1E-3},\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "107/107 [==============================] - 5s 43ms/step - loss: 0.0528 - atom_inf_mask_loss: 0.0372 - bur_vol_loss: 15.5152 - val_loss: 0.0417 - val_atom_inf_mask_loss: 0.0363 - val_bur_vol_loss: 5.4085\n",
      "Epoch 2/10\n",
      "107/107 [==============================] - 3s 29ms/step - loss: 0.0358 - atom_inf_mask_loss: 0.0313 - bur_vol_loss: 4.4545 - val_loss: 0.0401 - val_atom_inf_mask_loss: 0.0363 - val_bur_vol_loss: 3.7623\n",
      "Epoch 3/10\n",
      "107/107 [==============================] - 3s 28ms/step - loss: 0.0320 - atom_inf_mask_loss: 0.0286 - bur_vol_loss: 3.4102 - val_loss: 0.0392 - val_atom_inf_mask_loss: 0.0362 - val_bur_vol_loss: 3.0671\n",
      "Epoch 4/10\n",
      "107/107 [==============================] - 3s 28ms/step - loss: 0.0292 - atom_inf_mask_loss: 0.0263 - bur_vol_loss: 2.9010 - val_loss: 0.0363 - val_atom_inf_mask_loss: 0.0336 - val_bur_vol_loss: 2.7534\n",
      "Epoch 5/10\n",
      "107/107 [==============================] - 3s 28ms/step - loss: 0.0266 - atom_inf_mask_loss: 0.0239 - bur_vol_loss: 2.6235 - val_loss: 0.0359 - val_atom_inf_mask_loss: 0.0334 - val_bur_vol_loss: 2.5056\n",
      "Epoch 6/10\n",
      "107/107 [==============================] - 3s 29ms/step - loss: 0.0262 - atom_inf_mask_loss: 0.0238 - bur_vol_loss: 2.4426 - val_loss: 0.0412 - val_atom_inf_mask_loss: 0.0388 - val_bur_vol_loss: 2.3911\n",
      "Epoch 7/10\n",
      "107/107 [==============================] - 3s 28ms/step - loss: 0.0243 - atom_inf_mask_loss: 0.0220 - bur_vol_loss: 2.2948 - val_loss: 0.0380 - val_atom_inf_mask_loss: 0.0358 - val_bur_vol_loss: 2.2303\n",
      "Epoch 8/10\n",
      "107/107 [==============================] - 3s 28ms/step - loss: 0.0241 - atom_inf_mask_loss: 0.0219 - bur_vol_loss: 2.1938 - val_loss: 0.0380 - val_atom_inf_mask_loss: 0.0358 - val_bur_vol_loss: 2.1594\n",
      "Epoch 9/10\n",
      "107/107 [==============================] - 3s 28ms/step - loss: 0.0230 - atom_inf_mask_loss: 0.0209 - bur_vol_loss: 2.0972 - val_loss: 0.0372 - val_atom_inf_mask_loss: 0.0351 - val_bur_vol_loss: 2.0934\n",
      "Epoch 10/10\n",
      "107/107 [==============================] - 3s 28ms/step - loss: 0.0223 - atom_inf_mask_loss: 0.0203 - bur_vol_loss: 2.0220 - val_loss: 0.0370 - val_atom_inf_mask_loss: 0.0350 - val_bur_vol_loss: 2.0199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9ca8e3dc50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset,\n",
    "          validation_data=valid_dataset,\n",
    "          steps_per_epoch=math.ceil(num_train/batch_size),\n",
    "          validation_steps=math.ceil(5000/batch_size),\n",
    "          epochs=10,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
